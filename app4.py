import streamlit as st
import pandas as pd
import numpy as np
import warnings
import io
import time
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer
from sklearn.compose import ColumnTransformer
from imblearn.over_sampling import SMOTE
from sklearn.feature_selection import RFECV
from sklearn.decomposition import PCA
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier
from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, classification_report, f1_score, precision_score, recall_score, matthews_corrcoef
from scipy.stats import pearsonr, chi2_contingency
import shap
from fpdf import FPDF

st.set_page_config(
    page_title="Plataforma Preditiva de Reclama√ß√µes",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

warnings.filterwarnings('ignore')

class ProjectConfig:
    TARGET_VARIABLE = 'Complain'
    TEST_SIZE_RATIO = 0.3
    RANDOM_STATE_SEED = 42
    N_SPLITS_KFOLD = 5
    RFE_CV_SCORING = 'roc_auc'
    PRIMARY_COLOR = "#00A9FF"
    SECONDARY_COLOR = "#FF6347"
    BACKGROUND_COLOR = "#0A0A0A"
    TEXT_COLOR = "#EAEAEA"
    SUCCESS_COLOR = "#32CD32"
    GRID_COLOR = "#444444"

    @staticmethod
    def get_plotly_template():
        template = go.layout.Template()
        template.layout.paper_bgcolor = ProjectConfig.BACKGROUND_COLOR
        template.layout.plot_bgcolor = "#1E1E1E"
        template.layout.font = dict(color=ProjectConfig.TEXT_COLOR)
        template.layout.xaxis = dict(gridcolor=ProjectConfig.GRID_COLOR, linecolor=ProjectConfig.GRID_COLOR, showgrid=True, zeroline=False)
        template.layout.yaxis = dict(gridcolor=ProjectConfig.GRID_COLOR, linecolor=ProjectConfig.GRID_COLOR, showgrid=True, zeroline=False)
        template.layout.title = dict(x=0.5, font=dict(size=20))
        return template

def initialize_session_state():
    session_keys = {
        'app_stage': 'initialization',
        'data_loaded': False,
        'data_processed': False,
        'models_trained': False,
        'final_model_selected': False,
        'raw_df': None,
        'processed_df': None,
        'artifacts': {}
    }
    for key, default_value in session_keys.items():
        if key not in st.session_state:
            st.session_state[key] = default_value

initialize_session_state()
px.defaults.template = ProjectConfig.get_plotly_template()

@st.cache_data(show_spinner="Carregando e validando arquivo 'marketing_campaign.csv'...")
def load_data_from_disk():
    """L√™ o arquivo CSV diretamente do disco e o retorna como DataFrame."""
    try:
        df = pd.read_csv('marketing_campaign.csv', sep='\t')
        return df, "Arquivo 'marketing_campaign.csv' carregado com sucesso!"
    except FileNotFoundError:
        st.error("ERRO CR√çTICO: O arquivo 'marketing_campaign.csv' n√£o foi encontrado. Por favor, certifique-se de que ele est√° na mesma pasta que o seu script `app.py`.")
        return None, "Arquivo n√£o encontrado."
    except Exception as e:
        st.error(f"Erro inesperado ao ler o arquivo: {e}")
        return None, "Falha na leitura do arquivo."

@st.cache_data(show_spinner="Executando profiling detalhado dos dados...")
def perform_data_profiling(_df):
    """Executa um profiling completo no DataFrame, retornando um resumo detalhado."""
    # Renomeamos as chaves do dicion√°rio para serem mais amig√°veis ao usu√°rio
    profile_summary = {
        'Vis√£o Geral do Dataset': {
            'Total de Clientes (Linhas)': _df.shape[0],
            'Total de Caracter√≠sticas (Colunas)': _df.shape[1],
            'Dados Faltando (C√©lulas)': _df.isnull().sum().sum(),
            'Percentual de Dados Faltando': f"{(_df.isnull().sum().sum() / _df.size) * 100:.2f}%",
            'Registros Duplicados': _df.duplicated().sum(),
            'Uso de Mem√≥ria (MB)': f"{_df.memory_usage(deep=True).sum() / 1024**2:.2f}"
        },
        'detalhes_variaveis': []
    }
    for col in _df.columns:
        series = _df[col]
        # Tamb√©m renomeamos as chaves aqui
        col_info = {
            'Caracter√≠stica': col,
            'Tipo': str(series.dtype),
            'Dados Faltando': series.isnull().sum(),
            'Valores Distintos': series.nunique()
        }
        if pd.api.types.is_numeric_dtype(series):
            q1, q3 = series.quantile(0.25), series.quantile(0.75)
            iqr = q3 - q1
            outliers = series[(series < (q1 - 1.5 * iqr)) | (series > (q3 + 1.5 * iqr))]
            col_info['Valores At√≠picos (Outliers)'] = len(outliers)
            col_info['M√©dia'] = series.mean()
            col_info['Mediana'] = series.median()
            col_info['Desvio Padr√£o'] = series.std()
        profile_summary['detalhes_variaveis'].append(col_info)
    
    return profile_summary

@st.cache_data(show_spinner="Aplicando engenharia e transforma√ß√£o de features...")
def execute_feature_engineering(_df):
    """Executa um pipeline completo de limpeza, cria√ß√£o e transforma√ß√£o de vari√°veis."""
    df = _df.copy()
    if 'Income' in df.columns and df['Income'].isnull().any():
        df['Income'].fillna(df['Income'].median(), inplace=True)

    current_year = datetime.now().year
    df['Age'] = current_year - df['Year_Birth']
    df['Customer_Lifetime_Days'] = (datetime.now() - pd.to_datetime(df['Dt_Customer'], dayfirst=True)).dt.days
    df['Children_Total'] = df['Kidhome'] + df['Teenhome']
    
    mnt_cols = [col for col in df.columns if 'Mnt' in col]
    df['Total_Spent'] = df[mnt_cols].sum(axis=1)
    
    purchase_cols = [col for col in df.columns if 'Num' in col and 'Purchases' in col]
    df['Total_Purchases'] = df[purchase_cols].sum(axis=1)
    
    df['Luxury_Purchase_Ratio'] = (df['MntWines'] + df['MntGoldProds']) / (df['Total_Spent'] + 1)
    
    cmp_cols = [col for col in df.columns if 'AcceptedCmp' in col] + ['Response']
    df['Marketing_Engagements'] = df[cmp_cols].sum(axis=1)

    df['Marital_Status'] = df['Marital_Status'].replace({
        'Married': 'In_Relationship', 'Together': 'In_Relationship', 'Alone': 'Single',
        'Single': 'Single', 'Divorced': 'Single', 'Widow': 'Single', 'Absurd': 'Single', 'YOLO': 'Single'
    })
    df['Education'] = df['Education'].replace({'2n Cycle': 'Master'})
    
    cols_to_drop = [
        'ID', 'Year_Birth', 'Dt_Customer', 'Kidhome', 'Teenhome', 'Z_CostContact', 'Z_Revenue'
    ] + mnt_cols + cmp_cols
    df.drop(columns=cols_to_drop, inplace=True, errors='ignore')
    
    df.fillna(0, inplace=True)
    return df

def display_home_page():
    """Renderiza a p√°gina inicial/de boas-vindas do dashboard."""
    
    col1, col2 = st.columns([3, 1])
    with col1:
        st.title("Plataforma Preditiva de Reclama√ß√µes")
        st.subheader("Transformando Dados em Decis√µes Estrat√©gicas de Reten√ß√£o")
    with col2:
        st.image("https://www.gstatic.com/devrel-devsite/prod/v22d5bf23537453457d3952b9015c9ad5e229c66a7b204ada65f02540915f0119/developers/images/lockup-new.svg", width=200)

    st.markdown("---")
    
    st.markdown("""
    ### Bem-vindo √† Ferramenta Anal√≠tica de Modelagem Supervisionada.

    Esta plataforma interativa foi projetada para cumprir um objetivo de neg√≥cio claro: **prever quais clientes possuem a maior probabilidade de realizar uma reclama√ß√£o**.
    
    **O que voc√™ pode fazer aqui?**
    - **Analisar o Dataset:** Carregue e audite a qualidade dos dados dos clientes.
    - **Explorar os Dados:** Visualize de forma interativa a rela√ß√£o entre as vari√°veis.
    - **Construir e Avaliar Modelos:** Acompanhe o treinamento de m√∫ltiplos algoritmos e compare sua performance.
    - **Simular e Interpretar:** Utilize o modelo final para simular o impacto de campanhas de reten√ß√£o e entender os fatores que impulsionam as previs√µes.

    Utilize o **menu de navega√ß√£o na barra lateral esquerda** para explorar as diferentes etapas do projeto.
    """)
    
    st.markdown("---")
    
    with st.expander("Sobre este Projeto"):
        st.write("""
        Esta aplica√ß√£o √© o resultado pr√°tico da tarefa de Modelos Supervisionados, onde o desafio √© atuar como um cientista de dados para uma empresa de varejo. O foco n√£o est√° apenas em treinar modelos, mas em selecionar vari√°veis, testar abordagens, entender os algoritros e, o mais importante, transformar os resultados em a√ß√µes de neg√≥cio concretas.
        
        **Tecnologias Utilizadas:** Streamlit, Pandas, Scikit-learn, Plotly, SHAP.
        """)

    st.info("Para come√ßar, navegue para a p√°gina **'An√°lise do Dataset'** no menu lateral.", icon="üöÄ")

def display_dataset_page():
    """Renderiza a p√°gina de carregamento, profiling e engenharia de features."""
    
    st.header("An√°lise do Dataset: Carga e Auditoria de Qualidade")
    st.markdown("""
    O primeiro passo √© carregar e realizar uma auditoria completa nos dados. Isso nos permite entender a estrutura, identificar problemas
    como valores ausentes ou inconsistentes, e ter uma vis√£o geral da qualidade dos dados brutos antes de qualquer transforma√ß√£o.
    """)

    # Carregar os dados automaticamente do disco
    if not st.session_state.data_loaded:
        raw_df, message = load_data_from_disk()
        if raw_df is not None:
            st.session_state.raw_df = raw_df
            st.session_state.data_loaded = True
            st.success(message)
        else:
            st.error(message)
            return # Para a execu√ß√£o se o arquivo n√£o for encontrado

    if st.session_state.data_loaded:
        raw_df = st.session_state.raw_df
        # Exibir relat√≥rio de profiling
        profile_results = perform_data_profiling(raw_df)
        
        st.subheader("Vis√£o Geral do Dataset")
        overview = profile_results['Vis√£o Geral do Dataset']
        cols = st.columns(len(overview))
        for i, (key, value) in enumerate(overview.items()):
            cols[i].metric(key, value)
        
        with st.expander("Visualizar Relat√≥rio Detalhado por Vari√°vel", expanded=False):
            profile_df = pd.DataFrame(profile_results['detalhes_variaveis']).set_index('Caracter√≠stica')
            st.dataframe(profile_df)
        
        with st.expander("Visualizar Amostra dos Dados Brutos"):
            st.dataframe(raw_df.sample(5))

        st.markdown("---")
        
        st.subheader("Prepara√ß√£o e Enriquecimento dos Dados")
        st.markdown("""
        Ap√≥s a auditoria, executamos um pipeline de engenharia de features para limpar, transformar e enriquecer o dataset,
        criando novas vari√°veis que ajudar√£o os modelos a aprender melhor os padr√µes de comportamento dos clientes.
        """)
        
        if st.button("Executar Engenharia de Features", type="primary"):
            processed_df = execute_feature_engineering(st.session_state.raw_df)
            st.session_state.processed_df = processed_df
            st.session_state.data_processed = True
            st.success("Pipeline de engenharia de features executado com sucesso!")

        if st.session_state.data_processed:
            st.subheader("Amostra dos Dados Ap√≥s Transforma√ß√£o")
            st.markdown("Abaixo est√£o os dados prontos para a fase de an√°lise explorat√≥ria e modelagem.")
            st.dataframe(st.session_state.processed_df.sample(5))
            st.info("Os dados foram processados. Voc√™ j√° pode navegar para a 'An√°lise Explorat√≥ria' no menu lateral.", icon="üìä")

def display_eda_page():
    st.header("An√°lise Explorat√≥ria Interativa (EDA)")
    st.markdown("""
    Nesta se√ß√£o, mergulhamos nos dados para descobrir padr√µes, identificar anomalias e formular hip√≥teses. Utilize as abas abaixo para navegar entre os diferentes n√≠veis de an√°lise,
    desde o estudo de vari√°veis individuais at√© a visualiza√ß√£o de intera√ß√µes complexas entre m√∫ltiplos fatores.
    """)

    if not st.session_state.data_processed or st.session_state.processed_df is None:
        st.warning("Os dados precisam ser processados na p√°gina 'An√°lise do Dataset' para acessar a EDA.")
        return

    df = st.session_state.processed_df

    # Estrutura de abas para uma experi√™ncia de usu√°rio organizada
    tab_uni, tab_bi, tab_multi = st.tabs([
        "üìä An√°lise Univariada", 
        "üîó An√°lise Bivariada", 
        "üîÆ An√°lise Multivariada"
    ])

    with tab_uni:
        # A fun√ß√£o que renderiza o conte√∫do desta aba ser√° definida no pr√≥ximo bloco
        render_univariate_analysis_tab(df)

    with tab_bi:
        # A fun√ß√£o que renderiza o conte√∫do desta aba ser√° definida no bloco 7
        render_bivariate_analysis_tab(df)

    with tab_multi:
        # A fun√ß√£o que renderiza o conte√∫do desta aba ser√° definida no bloco 8
        render_multivariate_analysis_tab(df)

@st.cache_data
def calculate_descriptive_stats(series):
    """Calcula um dicion√°rio de estat√≠sticas descritivas para uma vari√°vel."""
    if pd.api.types.is_numeric_dtype(series):
        return {
            'M√©dia': series.mean(), 'Mediana': series.median(), 'Desvio Padr√£o': series.std(),
            'Vari√¢ncia': series.var(), 'M√≠nimo': series.min(), 'M√°ximo': series.max(),
            '25¬∫ Percentil': series.quantile(0.25), '75¬∫ Percentil': series.quantile(0.75),
            'Assimetria (Skew)': series.skew(), 'Curtose (Kurtosis)': series.kurt(),
            'Contagem': series.count(), 'Valores √önicos': series.nunique()
        }
    else:
        return {
            'Contagem': series.count(), 'Valores √önicos': series.nunique(),
            'Moda (Mais Frequente)': series.mode().iloc[0] if not series.mode().empty else 'N/A',
            'Frequ√™ncia da Moda': series.value_counts().iloc[0] if not series.value_counts().empty else 0
        }

def render_univariate_analysis_tab(df):
    st.subheader("An√°lise de Vari√°veis Individuais")
    st.markdown("Selecione uma vari√°vel para visualizar sua distribui√ß√£o e principais m√©tricas estat√≠sticas.")

    # Widget de sele√ß√£o para o usu√°rio
    variable_to_analyze = st.selectbox(
        "Selecione a vari√°vel de interesse:",
        options=df.columns,
        index=list(df.columns).index('Total_Spent') if 'Total_Spent' in df.columns else 0
    )

    if variable_to_analyze:
        selected_series = df[variable_to_analyze]
        
        # Layout principal com duas colunas
        stats_col, plot_col = st.columns([1, 2])
        
        with stats_col:
            st.markdown(f"#### M√©tricas para **{variable_to_analyze}**")
            stats_dict = calculate_descriptive_stats(selected_series)
            stats_df = pd.DataFrame(stats_dict.items(), columns=['M√©trica', 'Valor'])
            st.dataframe(stats_df, use_container_width=True)

        with plot_col:
            if pd.api.types.is_numeric_dtype(selected_series):
                st.markdown(f"#### Distribui√ß√£o de **{variable_to_analyze}**")
                
                # Gr√°fico com subplots para uma vis√£o completa
                fig = make_subplots(rows=2, cols=1, row_heights=[0.7, 0.3], vertical_spacing=0.05,
                                    subplot_titles=("Histograma e Curva de Densidade", "Box Plot para Detec√ß√£o de Outliers"))
                
                fig.add_trace(go.Histogram(x=selected_series, name='Histograma', histnorm='probability density'), row=1, col=1)
                fig.add_trace(go.Box(x=selected_series, name='Box Plot'), row=2, col=1)

                fig.update_layout(showlegend=False, height=500, margin=dict(t=40, b=10))
                st.plotly_chart(fig, use_container_width=True)
            
            else: 
                st.markdown(f"#### Frequ√™ncia de **{variable_to_analyze}**")
                
                counts = selected_series.value_counts()
                fig = px.bar(
                    counts, 
                    x=counts.index, 
                    y=counts.values,
                    title=f"Contagem de Categorias em {variable_to_analyze}",
                    labels={'x': variable_to_analyze, 'y': 'Contagem'},
                    text_auto=True
                )
                fig.update_layout(height=500)
                st.plotly_chart(fig, use_container_width=True)

def render_bivariate_analysis_tab(df):
    st.subheader("An√°lise de Rela√ß√£o entre Pares de Vari√°veis")
    st.markdown("Selecione duas vari√°veis para visualizar e quantificar a rela√ß√£o entre elas.")

    col1, col2 = st.columns(2)
    with col1:
        var1 = st.selectbox("Selecione a primeira vari√°vel:", df.columns, index=0, key="bivar_1")
    with col2:
        var2 = st.selectbox("Selecione a segunda vari√°vel:", df.columns, index=1, key="bivar_2")

    if var1 and var2 and var1 != var2:
        is_var1_numeric = pd.api.types.is_numeric_dtype(df[var1])
        is_var2_numeric = pd.api.types.is_numeric_dtype(df[var2])

        if is_var1_numeric and is_var2_numeric:
            st.markdown(f"#### An√°lise de Correla√ß√£o: **{var1}** vs. **{var2}**")
            
            corr, p_value = pearsonr(df[var1], df[var2])
            
            fig = px.scatter(
                df.sample(min(1000, len(df))),
                x=var1, y=var2,
                trendline="ols", trendline_color_override=ProjectConfig.SECONDARY_COLOR,
                title=f"Dispers√£o e Linha de Tend√™ncia"
            )
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)
            
            st.metric(label="Coeficiente de Correla√ß√£o de Pearson", value=f"{corr:.3f}")
            st.info(f"O p-valor para este teste de correla√ß√£o √© **{p_value:.4f}**. Valores de p < 0.05 geralmente indicam uma correla√ß√£o estatisticamente significante.", icon="üî¨")

        elif not is_var1_numeric and not is_var2_numeric:
            st.markdown(f"#### An√°lise de Associa√ß√£o: **{var1}** vs. **{var2}**")
            
            contingency_table = pd.crosstab(df[var1], df[var2])
            
            fig = px.bar(
                contingency_table,
                barmode='group',
                title=f"Contagem Agrupada"
            )
            fig.update_layout(height=500)
            st.plotly_chart(fig, use_container_width=True)

            chi2, p, _, _ = chi2_contingency(contingency_table)
            st.metric(label="Estat√≠stica Qui-Quadrado (œá¬≤)", value=f"{chi2:.2f}")
            st.info(f"O p-valor para o teste de independ√™ncia √© **{p:.4f}**. Valores de p < 0.05 sugerem que as vari√°veis s√£o dependentes (associadas).", icon="üî¨")

        else:
            numeric_var = var1 if is_var1_numeric else var2
            categorical_var = var2 if is_var1_numeric else var1
            
            st.markdown(f"#### Compara√ß√£o de Distribui√ß√µes: **{numeric_var}** por **{categorical_var}**")

            fig = px.violin(
                df, x=categorical_var, y=numeric_var,
                color=categorical_var, box=True, points="all",
                title=f"Distribui√ß√£o de {numeric_var} atrav√©s das categorias de {categorical_var}"
            )
            fig.update_layout(height=600)
            st.plotly_chart(fig, use_container_width=True)

            with st.expander("Ver resumo estat√≠stico detalhado por categoria"):
                st.dataframe(df.groupby(categorical_var)[numeric_var].describe().transpose())
    else:
        st.warning("Por favor, selecione duas vari√°veis diferentes para a an√°lise.")

@st.cache_data(show_spinner="Calculando proje√ß√£o PCA para visualiza√ß√£o...")
def get_pca_projection(_df, target_col):
    numeric_cols = _df.select_dtypes(include=np.number).columns.drop(target_col, errors='ignore')
    
    pca_df = _df.copy()
    pca_df[numeric_cols] = StandardScaler().fit_transform(pca_df[numeric_cols])
    
    pca = PCA(n_components=2, random_state=ProjectConfig.RANDOM_STATE_SEED)
    principal_components = pca.fit_transform(pca_df[numeric_cols])
    
    pca_result_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])
    pca_result_df[target_col] = pca_df[target_col].values
    
    explained_variance = pca.explained_variance_ratio_
    return pca_result_df, explained_variance

def render_multivariate_analysis_tab(df):
    st.subheader("An√°lise de M√∫ltiplas Vari√°veis Simultaneamente")
    st.markdown("Explore as intera√ß√µes complexas entre v√°rias features e como elas se relacionam com a vari√°vel alvo.")
    
    numeric_cols = df.select_dtypes(include=np.number).columns.drop(ProjectConfig.TARGET_VARIABLE, errors='ignore').tolist()
    
    st.markdown("#### Visualiza√ß√£o do Espa√ßo de Features com PCA")
    st.markdown("A An√°lise de Componentes Principais (PCA) reduz a complexidade dos dados, projetando-os em 2D. O gr√°fico abaixo nos ajuda a ver se existem agrupamentos naturais de clientes que reclamam (vermelho) vs. os que n√£o reclamam (azul).")

    if st.button("Gerar Gr√°fico PCA"):
        pca_result_df, explained_variance = get_pca_projection(df, ProjectConfig.TARGET_VARIABLE)
        
        fig_pca = px.scatter(
            pca_result_df, x='PC1', y='PC2',
            color=ProjectConfig.TARGET_VARIABLE,
            color_continuous_scale=[ProjectConfig.PRIMARY_COLOR, ProjectConfig.SECONDARY_COLOR],
            title=f"Proje√ß√£o PCA 2D do Dataset (Vari√¢ncia Explicada: {sum(explained_variance):.2%})"
        )
        fig_pca.update_layout(height=600)
        st.plotly_chart(fig_pca, use_container_width=True)
    
    st.markdown("---")
    
    st.markdown("#### Scatter Plot 3D Interativo")
    st.markdown("Selecione tr√™s vari√°veis num√©ricas para criar um gr√°fico de dispers√£o 3D. A cor dos pontos representa o status da reclama√ß√£o do cliente.")
    
    col1, col2, col3 = st.columns(3)
    with col1:
        x_3d = st.selectbox("Selecione o Eixo X:", numeric_cols, index=0, key="x_3d")
    with col2:
        y_3d = st.selectbox("Selecione o Eixo Y:", numeric_cols, index=1, key="y_3d")
    with col3:
        z_3d = st.selectbox("Selecione o Eixo Z:", numeric_cols, index=2, key="z_3d")
    
    if x_3d and y_3d and z_3d:
        fig_3d = px.scatter_3d(
            df.sample(min(2000, len(df))), # Amostra para performance
            x=x_3d, y=y_3d, z=z_3d,
            color=ProjectConfig.TARGET_VARIABLE,
            color_continuous_scale=[ProjectConfig.PRIMARY_COLOR, ProjectConfig.SECONDARY_COLOR],
            title="Visualiza√ß√£o 3D Interativa de Features",
            height=700
        )
        fig_3d.update_traces(marker=dict(size=3, opacity=0.8))
        st.plotly_chart(fig_3d, use_container_width=True)

@st.cache_data(show_spinner="Dividindo dados, processando e aplicando SMOTE...")
def prepare_data_for_modeling(_df, target, test_size, random_state):
    """Executa a divis√£o, pr√©-processamento e balanceamento dos dados."""
    
    X = _df.drop(columns=[target])
    y = _df[target]
    
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_size, random_state=random_state, stratify=y
    )
    
    numeric_features = X.select_dtypes(include=np.number).columns
    categorical_features = X.select_dtypes(exclude=np.number).columns
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_features),
            ('cat', OneHotEncoder(handle_unknown='ignore', drop='first'), categorical_features)
        ],
        remainder='passthrough'
    )
    
    X_train_processed = preprocessor.fit_transform(X_train)
    X_test_processed = preprocessor.transform(X_test)
    
    processed_feature_names = numeric_features.tolist() + \
                              preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features).tolist()

    smote = SMOTE(random_state=random_state)
    X_train_resampled, y_train_resampled = smote.fit_resample(X_train_processed, y_train)
    
    modeling_data = {
        'X_train_orig': X_train_processed, 'y_train_orig': y_train,
        'X_train_resampled': X_train_resampled, 'y_train_resampled': y_train_resampled,
        'X_test': X_test_processed, 'y_test': y_test,
        'preprocessor': preprocessor, 'processed_feature_names': processed_feature_names,
        'X_train_raw': X_train, 'X_test_raw': X_test
    }
    
    return modeling_data

def render_data_preparation_module(df):
    with st.container(border=True):
        st.subheader("Etapa 1: Prepara√ß√£o do Terreno para a Modelagem")
        st.markdown("""
        **O Qu√™?** Aqui, preparamos os dados para que os algoritmos de Machine Learning possam "entend√™-los" da melhor forma poss√≠vel. Realizamos tr√™s a√ß√µes cruciais:
        1.  **Divis√£o Estratificada:** Separamos os dados em um conjunto de **Treino** (para ensinar o modelo) e um de **Teste** (para avali√°-lo de forma imparcial). A estratifica√ß√£o garante que a propor√ß√£o de clientes que reclamam e n√£o reclamam seja a mesma em ambos os conjuntos, evitando vieses.
        2.  **Pr√©-processamento:** Padronizamos as vari√°veis num√©ricas (para que n√£o tenham escalas discrepantes) e codificamos as vari√°veis de texto em formato num√©rico.
        3.  **Balanceamento com SMOTE:** Nosso desafio √© que pouqu√≠ssimos clientes reclamam (~1%). Se n√£o fizermos nada, o modelo pode ficar "pregui√ßoso" e prever sempre "n√£o reclama". O **SMOTE** resolve isso criando exemplos sint√©ticos e realistas de clientes que reclamam no conjunto de treino. √â como dar uma lupa para o modelo aprender a fundo as caracter√≠sticas desse grupo minorit√°rio, mas crucial.
        
        **Por qu√™?** Esta etapa √© a funda√ß√£o de todo o projeto. Uma prepara√ß√£o inadequada levaria a modelos com performance ruim e conclus√µes de neg√≥cio equivocadas.
        """)
        
        if st.button("Executar Divis√£o e Balanceamento", type="primary", key="prep_button"):
            modeling_data = prepare_data_for_modeling(
                df, 
                target=ProjectConfig.TARGET_VARIABLE, 
                test_size=ProjectConfig.TEST_SIZE_RATIO, 
                random_state=ProjectConfig.RANDOM_STATE_SEED
            )
            st.session_state['artifacts']['modeling_data'] = modeling_data
            st.session_state.app_stage = 'data_prepared'
            st.success("Dados preparados com sucesso!")
            st.rerun()

    if 'modeling_data' in st.session_state.get('artifacts', {}):
        with st.container(border=True):
            modeling_data = st.session_state['artifacts']['modeling_data']
            st.subheader("An√°lise P√≥s-Prepara√ß√£o")
            st.markdown("""
            **O que aconteceu?** Os dados foram divididos e o SMOTE foi aplicado no conjunto de treino.
            - **M√©tricas:** Veja abaixo a quantidade de clientes em cada conjunto. Note como o conjunto de treino cresceu ap√≥s o balanceamento.
            - **Gr√°fico de Dispers√£o (PCA):** Este gr√°fico visualiza a "separa√ß√£o" entre clientes que reclamam (vermelho) e os que n√£o reclamam (azul) em um espa√ßo 2D. 
                - *Antes do SMOTE:* A nuvem de pontos vermelhos √© min√∫scula e dispersa, dif√≠cil para um modelo aprender.
                - *Depois do SMOTE:* A nuvem vermelha est√° muito mais densa e definida, criando um padr√£o claro para os algoritmos.
            
            **Pr√≥ximo Passo:** Agora que temos dados de alta qualidade, podemos prosseguir para a sele√ß√£o das vari√°veis mais importantes.
            """)
            
            col1, col2, col3 = st.columns(3)
            col1.metric("Clientes no Treino (Original)", len(modeling_data['y_train_orig']))
            col2.metric("Clientes no Teste", len(modeling_data['y_test']))
            col3.metric("Clientes no Treino (P√≥s-SMOTE)", len(modeling_data['y_train_resampled']), help="O n√∫mero aumentou devido aos exemplos sint√©ticos criados pelo SMOTE.")
            
            with st.expander("Visualizar Efeito do SMOTE (Proje√ß√£o PCA)"):
                pca_vis = PCA(n_components=2, random_state=ProjectConfig.RANDOM_STATE_SEED)
                X_train_pca_before = pca_vis.fit_transform(modeling_data['X_train_orig'])
                X_train_pca_after = pca_vis.transform(modeling_data['X_train_resampled'])

                df_before = pd.DataFrame(X_train_pca_before, columns=['PC1', 'PC2'])
                df_before['target'] = modeling_data['y_train_orig'].values
                df_after = pd.DataFrame(X_train_pca_after, columns=['PC1', 'PC2'])
                df_after['target'] = modeling_data['y_train_resampled'].values
                
                fig = make_subplots(rows=1, cols=2, subplot_titles=("Antes do SMOTE", "Depois do SMOTE"))
                fig.add_trace(go.Scatter(x=df_before['PC1'], y=df_before['PC2'], mode='markers', marker=dict(color=df_before['target'], colorscale=[ProjectConfig.PRIMARY_COLOR, ProjectConfig.SECONDARY_COLOR], showscale=False), name='Antes'), row=1, col=1)
                fig.add_trace(go.Scatter(x=df_after['PC1'], y=df_after['PC2'], mode='markers', marker=dict(color=df_after['target'], colorscale=[ProjectConfig.PRIMARY_COLOR, ProjectConfig.SECONDARY_COLOR], showscale=False), name='Depois'), row=1, col=2)
                st.plotly_chart(fig, use_container_width=True)

class ManualSelector:
    """Um seletor simulado para manter compatibilidade com o pipeline ap√≥s a sele√ß√£o manual de features."""
    def __init__(self, selected_indices):
        self.support_ = None
        self.selected_indices_ = selected_indices
    
    def fit(self, X):
        # Cria a m√°scara de suporte no momento do fit para ter a dimens√£o correta
        self.support_ = np.zeros(X.shape[1], dtype=bool)
        self.support_[self.selected_indices_] = True
    
    def transform(self, X):
        # Garante que o fit foi chamado antes do transform
        if self.support_ is None:
            raise RuntimeError("O m√©todo 'fit' deve ser chamado antes do 'transform'.")
        return X[:, self.support_]

@st.cache_data(show_spinner="Executando sele√ß√£o de features por import√¢ncia...")
def run_feature_selection_by_importance(_modeling_data, num_features_to_select):
    """Executa a sele√ß√£o de features baseada na import√¢ncia de um modelo LightGBM."""
    X_train, y_train = _modeling_data['X_train_resampled'], _modeling_data['y_train_resampled']
    
    estimator = LGBMClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED, n_jobs=-1, verbose=-1)
    estimator.fit(X_train, y_train)
    
    importances_df = pd.DataFrame({
        'Feature': _modeling_data['processed_feature_names'],
        'Importance': estimator.feature_importances_
    }).sort_values(by='Importance', ascending=False)
    
    top_features = importances_df.head(num_features_to_select)
    selected_features_names = top_features['Feature'].tolist()

    selected_indices = [
        _modeling_data['processed_feature_names'].index(f) for f in selected_features_names
    ]
    
    # Agora usamos a classe definida globalmente
    selector_object = ManualSelector(selected_indices)
    selector_object.fit(X_train) # Chama o fit para criar a m√°scara

    selection_artifacts = {
        'selector_object': selector_object,
        'optimal_n_features': num_features_to_select,
        'selected_feature_names': selected_features_names,
        'feature_ranking_df': importances_df,
    }
    return selection_artifacts

def render_feature_selection_module(modeling_data):
    with st.container(border=True):
        st.subheader("Etapa 2: Foco no que Importa - Sele√ß√£o R√°pida de Features")
        st.markdown("""
        **O Qu√™?** Para garantir uma experi√™ncia de usu√°rio r√°pida, substitu√≠mos o lento m√©todo RFECV por uma sele√ß√£o baseada em **import√¢ncia de features**. Treinamos um modelo LightGBM uma √∫nica vez e pedimos a ele para ranquear as vari√°veis da mais √† menos importante.
        
        **Por qu√™?** Esta abordagem √© extremamente r√°pida e eficaz. Ela nos permite identificar as vari√°veis com maior poder preditivo em segundos, em vez de minutos. Voc√™ pode usar o controle deslizante abaixo para definir interativamente quantas das melhores features deseja usar na modelagem.
        """)

        num_total_features = len(modeling_data['processed_feature_names'])
        num_features = st.slider(
            "Selecione quantas das features mais importantes voc√™ quer manter:",
            min_value=5,
            max_value=num_total_features,
            value=min(20, num_total_features), # Sugere 20 como um bom ponto de partida
            step=1
        )
        
        if st.button("Executar Sele√ß√£o R√°pida de Features", key="fs_button_fast"):
            # A execu√ß√£o agora √© quase instant√¢nea
            selection_artifacts = run_feature_selection_by_importance(modeling_data, num_features)
            st.session_state['artifacts']['selection_artifacts'] = selection_artifacts
            st.session_state.app_stage = 'features_selected'
            st.success("Sele√ß√£o de features conclu√≠da!")
            st.rerun()

    if 'selection_artifacts' in st.session_state.get('artifacts', {}):
        with st.container(border=True):
            artifacts = st.session_state['artifacts']['selection_artifacts']
            st.subheader("An√°lise P√≥s-Sele√ß√£o")
            st.markdown("""
            **O que aconteceu?** O modelo LightGBM foi treinado e ranqueou todas as features pela sua import√¢ncia. Selecionamos as **{n_feats}** melhores, conforme sua escolha.
            - **Gr√°fico de Import√¢ncia:** O gr√°fico abaixo mostra o ranking. As features no topo s√£o as que o modelo considera mais decisivas para prever uma reclama√ß√£o.
            - **Lista de Features:** Voc√™ pode expandir a se√ß√£o para ver a lista exata de features que ser√£o usadas na pr√≥xima etapa de modelagem.
            """.format(n_feats=artifacts['optimal_n_features']))
            
            # Gr√°fico de import√¢ncia das features
            ranking_df = artifacts['feature_ranking_df']
            fig = px.bar(
                ranking_df.head(30), # Mostra as 30 melhores
                x='Importance',
                y='Feature',
                orientation='h',
                title="Ranking de Import√¢ncia das Features (as 30 melhores)"
            )
            fig.update_layout(yaxis={'categoryorder':'total ascending'}, height=600)
            st.plotly_chart(fig, use_container_width=True)

            with st.expander("Ver Lista de Features Selecionadas para a Modelagem"):
                st.dataframe(pd.DataFrame(artifacts['selected_feature_names'], columns=["Feature Selecionada"]), use_container_width=True)

@st.cache_data(show_spinner="Treinando todos os 8 modelos de baseline... Este processo √© intensivo e pode levar alguns minutos.")
def train_all_baseline_models(_modeling_data, _selection_artifacts):
    """Treina um portf√≥lio de modelos e retorna seus resultados de performance."""
    selector = _selection_artifacts['selector_object']
    X_train_final = selector.transform(_modeling_data['X_train_resampled'])
    y_train = _modeling_data['y_train_resampled']
    X_test_final = selector.transform(_modeling_data['X_test'])
    y_test = _modeling_data['y_test']
    
    models_to_test = {
        "LightGBM": LGBMClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED, verbose=-1),
        "XGBoost": XGBClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED, use_label_encoder=False, eval_metric='logloss', verbosity=0),
        "Random Forest": RandomForestClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED),
        "Gradient Boosting": GradientBoostingClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED),
        "SVC": SVC(probability=True, random_state=ProjectConfig.RANDOM_STATE_SEED),
        "AdaBoost": AdaBoostClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED),
        "Decision Tree": DecisionTreeClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED),
        "KNN": KNeighborsClassifier(),
    }
    
    baseline_results = {}
    for name, model in models_to_test.items():
        start_time = time.time()
        model.fit(X_train_final, y_train)
        y_pred = model.predict(X_test_final)
        y_proba = model.predict_proba(X_test_final)[:, 1]
        end_time = time.time()
        
        metrics = {
            'AUC': roc_auc_score(y_test, y_proba),
            'Recall': recall_score(y_test, y_pred),
            'Precis√£o': precision_score(y_test, y_pred),
            'F1-Score': f1_score(y_test, y_pred),
            'MCC': matthews_corrcoef(y_test, y_pred),
            'Tempo de Treino (s)': end_time - start_time
        }
        
        baseline_results[name] = {
            'model_object': model, 'metrics': metrics,
            'full_report': classification_report(y_test, y_pred, output_dict=True, target_names=['N√£o Reclamou', 'Reclamou']),
            'confusion_matrix': confusion_matrix(y_test, y_pred),
            'roc_curve_data': roc_curve(y_test, y_proba)
        }
    return baseline_results

def render_baseline_modeling_module(modeling_data, selection_artifacts):
    with st.container(border=True):
        st.subheader("Etapa 3: A Competi√ß√£o dos Algoritmos (Baseline)")
        st.markdown("""
        **O Qu√™?** Agora come√ßa a parte divertida! Pegamos nossas features selecionadas e promovemos uma competi√ß√£o entre 8 diferentes algoritmos de Machine Learning. De modelos mais simples como √Årvores de Decis√£o a pot√™ncias como XGBoost e LightGBM, todos s√£o treinados na mesma base de dados para ver qual se adapta melhor ao nosso problema.

        **Por qu√™?** Essa abordagem de "campeonato" nos permite estabelecer uma **linha de base (baseline)** de performance. Em vez de apostar em um √∫nico algoritmo, testamos v√°rios para identificar objetivamente quais s√£o os mais promissores. Os modelos com melhor desempenho aqui ser√£o os candidatos para a fase de otimiza√ß√£o fina.
        """)
        
        if st.button("Iniciar Treinamento em Lote", key="train_button"):
            baseline_artifacts = train_all_baseline_models(modeling_data, selection_artifacts)
            st.session_state['artifacts']['baseline_artifacts'] = baseline_artifacts
            st.session_state.app_stage = 'baselines_trained'
            st.success("Treinamento em lote conclu√≠do!")
            st.rerun()

    if 'baseline_artifacts' in st.session_state.get('artifacts', {}):
        with st.container(border=True):
            artifacts = st.session_state['artifacts']['baseline_artifacts']
            st.subheader("An√°lise P√≥s-Treinamento: O Leaderboard")
            st.markdown("""
            **O que aconteceu?** Todos os 8 modelos foram treinados e avaliados no conjunto de teste. A tabela abaixo √© o nosso **Leaderboard de Performance**.
            
            **Como interpretar:**
            - **AUC:** A principal m√©trica de performance geral. Quanto maior (mais perto de 1.0), melhor o modelo consegue distinguir entre um cliente que vai reclamar e um que n√£o vai.
            - **Recall:** Extremamente importante para o neg√≥cio! Indica a porcentagem de clientes que **realmente reclamaram** e que o modelo conseguiu identificar corretamente. Um Recall alto significa que estamos deixando poucos "reclam√µes" passarem despercebidos.
            - **Precis√£o:** Dos clientes que o modelo **disse que iriam reclamar**, quantos de fato reclamaram.
            - **F1-Score:** Uma m√©dia harm√¥nica entre Precis√£o e Recall. √ötil para um balan√ßo geral.
            
            **Pr√≥ximo Passo:** Explore o leaderboard (voc√™ pode ordenar clicando no nome da coluna) para identificar os modelos campe√µes. A seguir, vamos mergulhar em uma an√°lise mais profunda de cada um deles e depois otimizar os melhores.
            """)
            
            leaderboard_data = [{'Modelo': name, **res['metrics']} for name, res in artifacts.items()]
            leaderboard_df = pd.DataFrame(leaderboard_data).set_index('Modelo')
            
            sort_by = st.selectbox("Ordenar leaderboard por:", leaderboard_df.columns, index=0)
            sorted_df = leaderboard_df.sort_values(by=sort_by, ascending=False)
            st.dataframe(sorted_df.style.background_gradient(cmap='viridis', subset=[sort_by]).format("{:.4f}"), use_container_width=True)

def display_modeling_page(df):
    st.header("Pipeline de Modelagem Preditiva", divider='rainbow')
    st.markdown("""
    Bem-vindo √† central de Machine Learning. Nesta p√°gina, executaremos o pipeline completo, desde a prepara√ß√£o dos dados at√© o treinamento e avalia√ß√£o de m√∫ltiplos modelos de classifica√ß√£o.
    Cada etapa foi projetada para ser executada sequencialmente, com explica√ß√µes detalhadas para que voc√™ entenda n√£o apenas **o que** est√° sendo feito, mas **por que** cada decis√£o √© crucial para o sucesso do projeto.
    """)

    if df is None or df.empty:
        st.error("‚ö†Ô∏è Os dados precisam ser processados na p√°gina 'An√°lise do Dataset' antes de iniciar a modelagem.")
        return

    # M√≥dulo 1: Prepara√ß√£o dos Dados
    render_data_preparation_module(df)
    
    # M√≥dulo 2: Sele√ß√£o de Features (s√≥ aparece se a etapa 1 foi conclu√≠da)
    if 'modeling_data' in st.session_state.get('artifacts', {}):
        render_feature_selection_module(st.session_state.artifacts['modeling_data'])
    
    # M√≥dulo 3: Treinamento de Baseline (s√≥ aparece se a etapa 2 foi conclu√≠da)
    if 'selection_artifacts' in st.session_state.get('artifacts', {}):
        render_baseline_modeling_module(st.session_state.artifacts['modeling_data'], st.session_state.artifacts['selection_artifacts'])
    
    # M√≥dulo 4: An√°lise Detalhada dos Modelos (s√≥ aparece se a etapa 3 foi conclu√≠da)
    if 'baseline_artifacts' in st.session_state.get('artifacts', {}):
        render_model_deep_dive_module(st.session_state.artifacts['baseline_artifacts'])
    
    # M√≥dulo 5: Otimiza√ß√£o de Hiperpar√¢metros (s√≥ aparece se a etapa 3 foi conclu√≠da)
    if 'baseline_artifacts' in st.session_state.get('artifacts', {}):
        render_hyperparameter_tuning_module(st.session_state.artifacts['baseline_artifacts'], st.session_state.artifacts['modeling_data'])
        
    # M√≥dulo 6: An√°lise do Modelo Final (s√≥ aparece se a etapa 5 foi conclu√≠da)
    if 'tuning_artifacts' in st.session_state.get('artifacts', {}):
        render_final_model_analysis_module(st.session_state.artifacts['tuning_artifacts'], st.session_state.artifacts['modeling_data'], st.session_state.artifacts['selection_artifacts'])

def render_model_deep_dive_module(baseline_artifacts):
    st.markdown("---")
    with st.container(border=True):
        st.subheader("Etapa 4: An√°lise Profunda dos Competidores")
        st.markdown("""
        **O Qu√™?** Agora, damos um "zoom" em cada modelo do leaderboard. Esta se√ß√£o permite que voc√™ investigue a performance de qualquer um dos algoritmos individualmente.
        
        **Por qu√™?** Entender *como* um modelo acerta e erra √© t√£o importante quanto sua pontua√ß√£o final. Analisaremos:
        - **Matriz de Confus√£o:** Um mapa dos acertos e erros. O erro mais cr√≠tico para n√≥s √© o **Falso Negativo**: quando o modelo prev√™ "N√£o Reclama" para um cliente que, na verdade, reclama. Esse √© o cliente insatisfeito que n√£o conseguimos identificar.
        - **Curva ROC:** Um gr√°fico que mostra a habilidade do modelo em separar as classes. Quanto mais a curva se aproxima do canto superior esquerdo, melhor.
        - **Import√¢ncia de Features:** Revela quais vari√°veis cada modelo espec√≠fico considerou mais importantes. Isso nos d√° as primeiras pistas sobre o "porqu√™" por tr√°s das previs√µes.
        """)
        
        model_to_inspect = st.selectbox(
            "Selecione um modelo do leaderboard para uma an√°lise detalhada:",
            options=baseline_artifacts.keys()
        )
        
        if model_to_inspect:
            model_data = baseline_artifacts[model_to_inspect]
            metrics = model_data['metrics']
            
            st.markdown(f"##### M√©tricas de Performance para o Modelo **{model_to_inspect}**")
            metric_cols = st.columns(4)
            metric_cols[0].metric("AUC", f"{metrics['AUC']:.4f}")
            metric_cols[1].metric("Recall", f"{metrics['Recall']:.4f}", help="Dos clientes que reclamaram, quantos o modelo pegou?")
            metric_cols[2].metric("Precis√£o", f"{metrics['Precis√£o']:.4f}", help="Dos clientes que o modelo disse que reclamariam, quantos realmente reclamaram?")
            metric_cols[3].metric("F1-Score", f"{metrics['F1-Score']:.4f}")

            tab_cm, tab_roc, tab_report, tab_importance = st.tabs(["Matriz de Confus√£o", "Curva ROC", "Relat√≥rio Completo", "Import√¢ncia de Features"])

            with tab_cm:
                cm = model_data['confusion_matrix']
                fig_cm = px.imshow(
                    cm, text_auto=True, aspect="auto",
                    labels=dict(x="Valores Previstos pelo Modelo", y="Valores Reais"),
                    x=['N√£o Reclamou', 'Reclamou'], y=['N√£o Reclamou', 'Reclamou'],
                    title=f"Matriz de Confus√£o para {model_to_inspect}",
                    color_continuous_scale='Blues'
                )
                fig_cm.update_layout(coloraxis_showscale=False)
                st.plotly_chart(fig_cm, use_container_width=True)
                st.info(f"O modelo identificou corretamente **{cm[1,1]}** clientes que reclamaram (Verdadeiros Positivos), mas falhou em identificar **{cm[1,0]}** (Falsos Negativos).")


            with tab_roc:
                fpr, tpr, _ = model_data['roc_curve_data']
                fig_roc = go.Figure()
                fig_roc.add_trace(go.Scatter(x=fpr, y=tpr, mode='lines', name=f'AUC = {metrics["AUC"]:.3f}', line=dict(width=4)))
                fig_roc.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode='lines', line=dict(dash='dash'), name='Performance Aleat√≥ria'))
                fig_roc.update_layout(title=f"Curva ROC para {model_to_inspect}", xaxis_title='Taxa de Falsos Positivos', yaxis_title='Taxa de Verdadeiros Positivos')
                st.plotly_chart(fig_roc, use_container_width=True)

            with tab_report:
                st.dataframe(pd.DataFrame(model_data['full_report']).transpose().style.format("{:.3f}"))

            with tab_importance:
                model_object = model_data['model_object']
                if hasattr(model_object, 'feature_importances_'):
                    feature_names = st.session_state['artifacts']['selection_artifacts']['selected_feature_names']
                    importance_df = pd.DataFrame({'Feature': feature_names, 'Import√¢ncia': model_object.feature_importances_})
                    importance_df = importance_df.sort_values(by='Import√¢ncia', ascending=True)
                    
                    fig_imp = px.bar(importance_df.tail(15), x='Import√¢ncia', y='Feature', orientation='h', title=f"Top 15 Features Mais Importantes ({model_to_inspect})")
                    fig_imp.update_layout(height=500)
                    st.plotly_chart(fig_imp, use_container_width=True)
                else:
                    st.info(f"O modelo '{model_to_inspect}' n√£o possui um atributo '.feature_importances_' para an√°lise direta de import√¢ncia (ex: SVM com kernel n√£o-linear).")


@st.cache_data(show_spinner="Executando busca em grade para otimiza√ß√£o de hiperpar√¢metros...")
def run_hyperparameter_tuning(_baseline_artifacts, _modeling_data, top_n_models):
    """Executa GridSearchCV nos N melhores modelos do baseline."""
    X_train_final = st.session_state['artifacts']['selection_artifacts']['selector_object'].transform(_modeling_data['X_train_resampled'])
    y_train = _modeling_data['y_train_resampled']
    
    leaderboard_df = pd.DataFrame([{'Modelo': name, 'AUC': res['metrics']['AUC']} for name, res in _baseline_artifacts.items()]).set_index('Modelo').sort_values(by='AUC', ascending=False)
    models_to_tune = leaderboard_df.head(top_n_models).index.tolist()
    
    param_grids = {
        "LightGBM": {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.05, 0.1], 'num_leaves': [20, 31, 40]},
        "XGBoost": {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.05, 0.1], 'max_depth': [3, 5, 7]},
        "Random Forest": {'n_estimators': [100, 200], 'max_depth': [10, 20, None], 'min_samples_leaf': [1, 2, 4]},
        "Gradient Boosting": {'n_estimators': [100, 200], 'learning_rate': [0.05, 0.1], 'max_depth': [3, 5]},
        "SVC": {'C': [1, 10, 50], 'gamma': ['scale', 'auto'], 'kernel': ['rbf']}
    }
    
    model_initializers = {
        "LightGBM": LGBMClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED, verbose=-1),
        "XGBoost": XGBClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED, use_label_encoder=False, eval_metric='logloss', verbosity=0),
        "Random Forest": RandomForestClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED),
        "Gradient Boosting": GradientBoostingClassifier(random_state=ProjectConfig.RANDOM_STATE_SEED),
        "SVC": SVC(probability=True, random_state=ProjectConfig.RANDOM_STATE_SEED)
    }

    tuning_results = {}
    for model_name in models_to_tune:
        if model_name in param_grids:
            base_model = model_initializers[model_name]
            grid_search = GridSearchCV(estimator=base_model, param_grid=param_grids[model_name], cv=3, scoring='roc_auc', n_jobs=-1, verbose=1)
            grid_search.fit(X_train_final, y_train)
            tuning_results[model_name] = {'best_estimator': grid_search.best_estimator_, 'best_params': grid_search.best_params_, 'best_score_cv': grid_search.best_score_}
    return tuning_results

def render_hyperparameter_tuning_module(baseline_artifacts, modeling_data):
    st.markdown("---")
    with st.container(border=True):
        st.subheader("Etapa 5: Ajuste Fino dos Campe√µes (Otimiza√ß√£o)")
        st.markdown("""
        **O Qu√™?** Selecionamos os melhores modelos da fase anterior e os submetemos a um "ajuste fino". Se um modelo fosse um carro de corrida, esta etapa seria como levar os melhores carros para uma oficina especializada para ajustar o motor, a suspens√£o e a aerodin√¢mica para extrair cada gota de performance. Tecnicamente, chamamos isso de **Otimiza√ß√£o de Hiperpar√¢metros**.
        
        **Por qu√™?** Os modelos v√™m com configura√ß√µes padr√£o. A otimiza√ß√£o testa centenas de combina√ß√µes dessas configura√ß√µes (usando `GridSearchCV`) para encontrar a combina√ß√£o perfeita que maximiza o poder preditivo do nosso modelo para este problema espec√≠fico.
        """)
        
        top_n = st.slider("Selecione quantos dos melhores modelos voc√™ deseja otimizar:", 1, 3, 2, key="tuner_slider")
        
        if st.button("Iniciar Otimiza√ß√£o dos Melhores Modelos", key="tune_button"):
            tuning_artifacts = run_hyperparameter_tuning(baseline_artifacts, modeling_data, top_n)
            st.session_state['artifacts']['tuning_artifacts'] = tuning_artifacts
            st.session_state.app_stage = 'models_tuned'
            st.success("Otimiza√ß√£o conclu√≠da!")
            st.rerun()

    if 'tuning_artifacts' in st.session_state.get('artifacts', {}):
        with st.container(border=True):
            artifacts = st.session_state['artifacts']['tuning_artifacts']
            st.subheader("An√°lise P√≥s-Otimiza√ß√£o")
            st.markdown("""
            **O que aconteceu?** O `GridSearchCV` testou v√°rias configura√ß√µes e encontrou a melhor para cada modelo.
            - **Resultados:** Abaixo, comparamos o desempenho do modelo antes (AUC Original) e depois do ajuste (AUC Otimizado). O "delta" mostra o ganho de performance. Mesmo um pequeno aumento percentual na AUC pode representar a identifica√ß√£o correta de dezenas de clientes em risco.
            - **Melhores Par√¢metros:** Mostramos as configura√ß√µes exatas que geraram o melhor resultado.
            
            **Pr√≥ximo Passo:** Com os modelos em sua performance m√°xima, estamos prontos para selecionar o grande campe√£o e analis√°-lo sob a √≥tica do neg√≥cio.
            """)
            
            for model_name, results in artifacts.items():
                st.markdown(f"##### **{model_name}**")
                original_auc = baseline_artifacts[model_name]['metrics']['AUC']
                tuned_cv_auc = results['best_score_cv']
                
                col1, col2 = st.columns([1, 2])
                with col1:
                    st.metric("AUC Original (em teste)", f"{original_auc:.4f}")
                    st.metric("AUC Otimizado (em treino)", f"{tuned_cv_auc:.4f}", delta=f"{(tuned_cv_auc - original_auc):.4f}", help="A melhora √© calculada em rela√ß√£o ao AUC original. O AUC otimizado √© medido na valida√ß√£o cruzada do treino.")
                with col2:
                    st.write("**Melhores Par√¢metros Encontrados:**")
                    st.json(results['best_params'])

@st.cache_data
def select_and_evaluate_final_model(_tuning_artifacts, _modeling_data, _selection_artifacts):
    """Seleciona o melhor modelo ap√≥s o tuning e realiza uma avalia√ß√£o final completa."""
    best_model_name = max(_tuning_artifacts, key=lambda k: _tuning_artifacts[k]['best_score_cv'])
    final_model = _tuning_artifacts[best_model_name]['best_estimator']
    
    X_test_final = _selection_artifacts['selector_object'].transform(_modeling_data['X_test'])
    y_test = _modeling_data['y_test']
    
    y_proba_final = final_model.predict_proba(X_test_final)[:, 1]
    
    from sklearn.metrics import precision_recall_curve, average_precision_score
    precision_data, recall_data, thresholds = precision_recall_curve(y_test, y_proba_final)
    
    final_artifacts = {
        'model_name': best_model_name,
        'model_object': final_model,
        'predictions_proba': y_proba_final,
        'precision_recall_curve': (precision_data, recall_data, thresholds),
        'avg_precision_score': average_precision_score(y_test, y_proba_final)
    }
    return final_artifacts

def render_final_model_analysis_module(tuning_artifacts, modeling_data, selection_artifacts):
    st.markdown("---")
    with st.container(border=True):
        st.subheader("Etapa 6: O Modelo Campe√£o e a Decis√£o de Neg√≥cio")
        st.markdown("""
        **O Qu√™?** Chegamos √† fase final da modelagem. Aqui, selecionamos o modelo com a melhor performance ap√≥s a otimiza√ß√£o e o analisamos sob a √≥tica mais importante: a de neg√≥cio.
        
        **Por qu√™?** Um modelo n√£o toma decis√µes sozinho. Ele nos d√° uma **probabilidade** de um cliente reclamar. N√≥s, humanos, precisamos definir o **limiar de decis√£o**: qual o n√≠vel de probabilidade (ex: 30%, 50%, 70%) que usaremos para classificar um cliente como "de risco" e agir? Essa escolha envolve um trade-off:
        - **Limiar Baixo:** Capturamos mais clientes que reclamam (**Recall alto**), mas tamb√©m contatamos mais clientes que n√£o reclamariam (**Precis√£o baixa**). Custo da a√ß√£o √© maior.
        - **Limiar Alto:** Somos mais seletivos, contatando apenas os casos mais prov√°veis (**Precis√£o alta**), mas arriscamos perder alguns clientes que reclamam (**Recall baixo**). Custo do risco √© maior.
        
        A ferramenta interativa abaixo permite que voc√™ simule esse trade-off e escolha o ponto de equil√≠brio ideal para a estrat√©gia da empresa.
        """)

        if st.button("Selecionar e Analisar Modelo Campe√£o", key="final_model_button", type='primary'):
            final_model_artifacts = select_and_evaluate_final_model(tuning_artifacts, modeling_data, selection_artifacts)
            st.session_state['artifacts']['final_model_artifacts'] = final_model_artifacts
            st.session_state.app_stage = 'final_model_selected'
            st.success("An√°lise do modelo final conclu√≠da!")
            st.rerun()

    if 'final_model_artifacts' in st.session_state.get('artifacts', {}):
        with st.container(border=True):
            artifacts = st.session_state['artifacts']['final_model_artifacts']
            st.subheader(f"An√°lise de Trade-off para o Modelo Campe√£o: {artifacts['model_name']}")
            st.success(f"O modelo campe√£o, **{artifacts['model_name']}**, foi selecionado com base na melhor performance de AUC na otimiza√ß√£o.")

            st.markdown("#### An√°lise Interativa do Limiar de Decis√£o")
            st.markdown("Use o slider abaixo para definir o **limiar de probabilidade**. Observe como as m√©tricas de **Recall** e **Precis√£o** mudam. Sua tarefa √© encontrar o balan√ßo ideal: qual o m√≠nimo de Recall que a empresa aceita? Qual a m√°xima precis√£o que podemos atingir para esse Recall?")
            
            decision_threshold = st.slider("Arraste para ajustar o limiar de decis√£o de risco:", 0.0, 1.0, 0.5, 0.01)
            
            y_pred_adj = (artifacts['predictions_proba'] >= decision_threshold).astype(int)
            y_test = modeling_data['y_test']

            adj_recall = recall_score(y_test, y_pred_adj)
            adj_precision = precision_score(y_test, y_pred_adj)
            adj_f1 = f1_score(y_test, y_pred_adj)
            
            cols = st.columns(3)
            cols[0].metric("Recall com Limiar Ajustado", f"{adj_recall:.2%}")
            cols[1].metric("Precis√£o com Limiar Ajustado", f"{adj_precision:.2%}")
            cols[2].metric("F1-Score com Limiar Ajustado", f"{adj_f1:.2%}")

            st.markdown("#### Curva de Precis√£o x Recall")
            st.markdown("Este gr√°fico resume o trade-off. Ele mostra a precis√£o que obtemos para cada n√≠vel de recall. Uma √°rea maior sob a curva indica um modelo melhor.")
            pr_precision, pr_recall, _ = artifacts['precision_recall_curve']
            fig = px.area(x=pr_recall[1:], y=pr_precision[1:], title=f"Curva de Precis√£o-Recall (√Årea = {artifacts['avg_precision_score']:.3f})", labels=dict(x="Recall (Capacidade de encontrar quem reclama)", y="Precis√£o (Assertividade das previs√µes de risco)"))
            fig.add_shape(type='line', x0=adj_recall, y0=0, x1=adj_recall, y1=adj_precision, line=dict(color='red', dash='dash'))
            fig.add_shape(type='line', x0=0, y0=adj_precision, x1=adj_recall, y1=adj_precision, line=dict(color='red', dash='dash'))
            fig.add_annotation(x=adj_recall, y=adj_precision, text=f"Ponto Atual ({adj_recall:.2f}, {adj_precision:.2f})", showarrow=True)
            fig.update_yaxes(range=[0, 1.05])
            fig.update_xaxes(range=[0, 1.05])
            st.plotly_chart(fig, use_container_width=True)

            st.info("""
            **Conclus√£o e Pr√≥ximo Passo:** Agora que voc√™ pode definir uma estrat√©gia de neg√≥cio (o limiar), navegue para a p√°gina **"An√°lise Avan√ßada e de Neg√≥cio"**. L√°, usaremos este modelo final e o limiar escolhido para entender *quais* clientes s√£o de risco (interpretabilidade) e simular o impacto financeiro de uma campanha de reten√ß√£o (an√°lise de ROI).
            """, icon="üí°")

def display_advanced_analysis_page():
    st.header("An√°lise Avan√ßada e de Neg√≥cio", anchor=False)
    st.markdown("""
    Nesta se√ß√£o final, vamos al√©m das m√©tricas de performance para extrair o m√°ximo de valor do nosso modelo. Aqui, vamos interpretar suas decis√µes,
    simular o impacto financeiro de nossas a√ß√µes e preparar os resultados para serem compartilhados.
    """)

    if not st.session_state.get('app_stage') == 'final_model_selected':
        st.warning("Por favor, execute todo o pipeline na p√°gina 'Modelagem e Avalia√ß√£o' para acessar a An√°lise Avan√ßada.")
        st.info("Voc√™ precisa clicar no bot√£o 'Selecionar e Analisar Modelo Campe√£o' na p√°gina anterior.")
        return

    # Se todas as etapas foram conclu√≠das, os artefatos estar√£o dispon√≠veis na sess√£o
    final_model_artifacts = st.session_state['artifacts']['final_model_artifacts']
    modeling_data = st.session_state['artifacts']['modeling_data']
    selection_artifacts = st.session_state['artifacts']['selection_artifacts']
    processed_df = st.session_state['processed_df']
    
    # Estrutura de abas para organizar a an√°lise avan√ßada
    tab_xai, tab_roi, tab_export = st.tabs(["ü§ñ Interpretabilidade do Modelo (XAI)", "üìà Simula√ß√£o de ROI", "üì§ Exportar Resultados"])
    
    with tab_xai:
        render_global_xai_module(final_model_artifacts, modeling_data, selection_artifacts)
        render_local_xai_module(final_model_artifacts, modeling_data, selection_artifacts)
        
    with tab_roi:
        render_business_impact_module(final_model_artifacts, modeling_data)
        
    with tab_export:
        render_export_module(final_model_artifacts, selection_artifacts, processed_df)

@st.cache_data(show_spinner="Calculando valores SHAP para interpretabilidade global...")
def calculate_global_shap_values(_final_model_artifacts, _modeling_data, _selection_artifacts):
    """Calcula os valores SHAP para uma amostra dos dados de treino."""
    model = _final_model_artifacts['model_object']
    X_train_final = _selection_artifacts['selector_object'].transform(_modeling_data['X_train_resampled'])
    
    # SHAP requer que o explainer seja treinado nos mesmos dados que o modelo
    X_train_sample = shap.sample(X_train_final, 200) # Amostra para performance
    explainer = shap.TreeExplainer(model, X_train_sample)
    
    # Usar uma amostra de teste para a visualiza√ß√£o, para ser mais representativo do desempenho real
    X_test_final = _selection_artifacts['selector_object'].transform(_modeling_data['X_test'])
    X_test_sample = shap.sample(X_test_final, 200)
    
    shap_values = explainer.shap_values(X_test_sample)
    
    feature_names = _selection_artifacts['selected_feature_names']
    
    shap_artifacts = {
        'explainer': explainer,
        'shap_values': shap_values,
        'X_sample': X_test_sample,
        'feature_names': feature_names
    }
    return shap_artifacts

def render_global_xai_module(final_model_artifacts, modeling_data, selection_artifacts):
    with st.container(border=True):
        st.subheader("An√°lise de Interpretabilidade Global (XAI com SHAP)")
        st.markdown("Aqui, abrimos a 'caixa-preta' do modelo para entender quais fatores ele considera mais importantes em suas decis√µes, de forma geral.")
        
        if 'shap_artifacts' not in st.session_state.get('artifacts', {}):
            if st.button("Gerar An√°lise de Interpretabilidade Global", key="xai_button"):
                shap_artifacts = calculate_global_shap_values(final_model_artifacts, modeling_data, selection_artifacts)
                st.session_state['artifacts']['shap_artifacts'] = shap_artifacts
                st.rerun()
        
        if 'shap_artifacts' in st.session_state.get('artifacts', {}):
            artifacts = st.session_state['artifacts']['shap_artifacts']
            shap_values_for_plot = artifacts['shap_values'][1] if isinstance(artifacts['shap_values'], list) else artifacts['shap_values']
            X_sample_df = pd.DataFrame(artifacts['X_sample'], columns=artifacts['feature_names'])
            
            st.markdown("#### Import√¢ncia Geral das Features (SHAP Bar Plot)")
            st.markdown("Este gr√°fico ranqueia as features pelo seu impacto m√©dio absoluto nas previs√µes.")
            fig_bar, ax_bar = plt.subplots()
            shap.summary_plot(shap_values_for_plot, X_sample_df, plot_type="bar", show=False)
            st.pyplot(fig_bar)
            
            st.markdown("#### Impacto e Distribui√ß√£o das Features (SHAP Beeswarm Plot)")
            st.markdown("""
            Este gr√°fico mostra o impacto de cada feature para cada cliente da amostra.
            - **Eixo X:** Valor SHAP (impacto na previs√£o). Valores positivos aumentam o risco.
            - **Cor:** Valor da feature (vermelho = alto, azul = baixo).
            """)
            fig_beeswarm, ax_beeswarm = plt.subplots()
            shap.summary_plot(shap_values_for_plot, X_sample_df, plot_type='dot', show=False)
            st.pyplot(fig_beeswarm)

# Insira este bloco de c√≥digo no lugar das duas fun√ß√µes que voc√™ apagou

def render_local_xai_module(final_model_artifacts, modeling_data, selection_artifacts):
    with st.container(border=True):
        st.subheader("An√°lise de Previs√£o Individual (Interpretabilidade Local)")
        st.markdown("""
        Entenda o **porqu√™** de uma previs√£o para um cliente espec√≠fico. Crie um perfil de cliente abaixo para gerar um score de risco e um 
        **Force Plot** do SHAP, que explica quais fatores mais influenciaram a decis√£o do modelo para este caso.
        """)
        
        X_train_orig = modeling_data['X_train_raw']

        with st.form("local_prediction_form"):
            st.markdown("##### Simulador de Perfil de Cliente")
            
            form_cols = st.columns(3)
            input_values = {}
            
            integer_features = ['Recency', 'Age', 'Marketing_Engagements', 'Total_Purchases', 'Children_Total']
            all_numeric_features = [
                'Total_Spent', 'Recency', 'Income', 'Customer_Lifetime_Days', 
                'Age', 'Marketing_Engagements', 'Luxury_Purchase_Ratio', 
                'Total_Purchases', 'Children_Total'
            ]
            
            for i, feature in enumerate(all_numeric_features):
                with form_cols[i % 3]:
                    if feature in X_train_orig.columns:
                        series = X_train_orig[feature]
                        
                        if feature in integer_features:
                            min_val, max_val, mean_val = int(series.min()), int(series.max()), int(series.mean())
                            # AJUSTE 2: Remo√ß√£o do sufixo "(Inteiro)"
                            input_values[feature] = st.slider(
                                f"Valor para '{feature}'", 
                                min_val, max_val, mean_val, step=1
                            )
                        else: 
                            min_val, max_val, mean_val = float(series.min()), float(series.max()), float(series.mean())
                            step = 0.01 if feature == 'Luxury_Purchase_Ratio' else 1.0
                            # AJUSTE 2: Remo√ß√£o do sufixo "(Decimal)"
                            input_values[feature] = st.number_input(
                                f"Valor para '{feature}'",
                                min_val, max_val, mean_val, step=step
                            )

            # Mant√©m os seletores para vari√°veis categ√≥ricas
            with form_cols[len(all_numeric_features) % 3]:
                 input_values['Education'] = st.selectbox("Educa√ß√£o", X_train_orig['Education'].unique())
            with form_cols[(len(all_numeric_features) + 1) % 3]:
                 input_values['Marital_Status'] = st.selectbox("Estado Civil", X_train_orig['Marital_Status'].unique())

            submit_button = st.form_submit_button("Analisar Previs√£o para este Perfil", type="primary")

        if submit_button:
            with st.spinner("Calculando previs√£o e explica√ß√£o SHAP local..."):
                full_input_df = X_train_orig.iloc[0:1].copy()
                for feature, value in input_values.items():
                    if feature in full_input_df.columns:
                        full_input_df[feature] = value
                
                preprocessor = modeling_data['preprocessor']
                selector = selection_artifacts['selector_object']
                
                input_processed = preprocessor.transform(full_input_df)
                input_final = selector.transform(input_processed)
                
                model = final_model_artifacts['model_object']
                explainer = shap.Explainer(model, st.session_state.artifacts['shap_artifacts']['X_sample'])
                shap_values_local = explainer(input_final)

                prediction_proba = model.predict_proba(input_final)[0][1]

                st.metric("Probabilidade de Reclama√ß√£o para este Cliente", f"{prediction_proba:.2%}")

                st.markdown("##### Explica√ß√£o Visual da Previs√£o (SHAP Force Plot)")
                
                force_plot = shap.force_plot(
                    shap_values_local[0],
                    feature_names=selection_artifacts['selected_feature_names']
                )
                
                shap_html = f"<head>{shap.getjs()}</head><body><div style='background-color: white; padding: 15px; border-radius: 5px;'>{force_plot.html()}</div></body>"
                st.components.v1.html(shap_html, height=200, scrolling=True)

                # AJUSTE 3: Adi√ß√£o da explica√ß√£o textual do gr√°fico SHAP
                st.markdown("---")
                st.markdown("#### An√°lise do Gr√°fico")
                st.info(
                    """
                    **Como interpretar o gr√°fico acima:**

                    O gr√°fico de for√ßa do SHAP mostra como cada caracter√≠stica do cliente empurra a previs√£o do modelo para longe ou para perto do resultado final.

                    - **Valor Base (base value):** √â a probabilidade m√©dia de reclama√ß√£o em todo o conjunto de dados. Pense nele como o ponto de partida da previs√£o antes de conhecermos as caracter√≠sticas deste cliente espec√≠fico.

                    - **Setas Vermelhas (Fatores de Risco):** S√£o as caracter√≠sticas que **aumentam** a probabilidade de reclama√ß√£o para o perfil simulado. Quanto maior a seta, maior o impacto daquela caracter√≠stica na eleva√ß√£o do risco.

                    - **Setas Azuis (Fatores de Prote√ß√£o):** S√£o as caracter√≠sticas que **diminuem** a probabilidade de reclama√ß√£o. Quanto maior a seta, mais aquela caracter√≠stica contribui para classificar o cliente como de baixo risco.

                    **An√°lise Pr√°tica:** Observe as maiores setas vermelhas. Elas representam os principais motivos pelos quais o modelo considera este cliente propenso a reclamar. Uma a√ß√£o de reten√ß√£o eficaz deveria focar em mitigar os problemas relacionados a esses fatores.
                    """, icon="üí°"
                )

def render_business_impact_module(final_model_artifacts, modeling_data):
    # AJUSTE 1: Revers√£o para premissas antigas e ajuste de limites de valores.
    with st.container(border=True):
        st.subheader("Simula√ß√£o de Impacto no Neg√≥cio e An√°lise de ROI")
        st.markdown("""
        Esta ferramenta calcula o potencial de economia ao implementar uma campanha de reten√ß√£o proativa.
        A l√≥gica √© simples: comparamos o custo de contatar preventivamente os clientes de risco versus o custo de tratar suas reclama√ß√µes de forma reativa.
        """)

        st.markdown("##### 1. Defina as Premissas Financeiras e Operacionais")
        col1, col2, col3 = st.columns(3)
        with col1:
            cost_proactive = st.number_input("Custo por Contato Proativo (R$)", 0.0, 100000.0, 15.0, 1.0, help="Custo de uma a√ß√£o preventiva (liga√ß√£o, voucher, etc.).")
        with col2:
            cost_reactive = st.number_input("Custo por Reclama√ß√£o Reativa (R$)", 0.0, 100000.0, 150.0, 10.0, help="Custo total para resolver uma reclama√ß√£o que j√° aconteceu (horas de suporte, compensa√ß√£o, etc.).")
        with col3:
            effectiveness = st.slider("Efetividade da A√ß√£o Proativa (%)", 0, 100, 50, help="Qual a % de reclama√ß√µes que a a√ß√£o proativa consegue evitar?")

        st.markdown("##### 2. Defina o P√∫blico-Alvo da Campanha com o Limiar de Risco")
        decision_threshold = st.slider("Contatar clientes com probabilidade de reclama√ß√£o acima de:", 0.0, 1.0, 0.5, 0.01, help="Limiar de decis√£o do modelo para classificar um cliente como 'de risco'.")

        y_proba = final_model_artifacts['predictions_proba']
        y_test = modeling_data['y_test'].values
        predictions_as_risk = (y_proba >= decision_threshold)
        
        try:
            tn, fp, fn, tp = confusion_matrix(y_test, predictions_as_risk).ravel()
        except ValueError:
            st.warning("O limiar escolhido n√£o identificou clientes em nenhuma categoria. Ajuste o limiar.")
            return

        # --- C√°lculos da Simula√ß√£o ---
        customers_to_contact = tp + fp
        campaign_total_cost = customers_to_contact * cost_proactive
        
        potential_complaints_targeted = tp
        complaints_avoided = potential_complaints_targeted * (effectiveness / 100.0)
        
        cost_avoided = complaints_avoided * cost_reactive
        
        net_value = cost_avoided - campaign_total_cost
        roi = (net_value / campaign_total_cost) * 100 if campaign_total_cost > 0 else 0

        st.markdown("---")
        st.markdown("##### 3. Resultados da Simula√ß√£o Financeira")
        
        st.markdown("##### Visualiza√ß√£o do Retorno Sobre o Investimento (ROI)")
        
        fig_roi = go.Figure(go.Indicator(
            mode = "gauge+number",
            value = roi,
            number = {'suffix': "%"},
            title = {'text': "ROI da Campanha Proativa"},
            domain = {'x': [0, 1], 'y': [0, 1]},
            gauge = {
                'axis': {'range': [-100, 200], 'tickwidth': 1, 'tickcolor': "darkgray"},
                'bar': {'color': ProjectConfig.PRIMARY_COLOR, 'thickness': 0.3},
                'bgcolor': "white",
                'borderwidth': 2,
                'bordercolor': "gray",
                'steps': [
                    {'range': [-100, 0], 'color': '#FF6347'}, # Cor para ROI negativo
                    {'range': [0, 50], 'color': '#FFD700'},    # Cor para ROI modesto
                    {'range': [50, 200], 'color': '#32CD32'}], # Cor para ROI alto
            }))
        
        fig_roi.update_layout(height=350, margin=dict(t=50, b=10))
        st.plotly_chart(fig_roi, use_container_width=True)

        res_col3, res_col4, res_col5 = st.columns(3)
        res_col3.metric("Custo da Campanha Proativa", f"R$ {campaign_total_cost:,.2f}")
        res_col4.metric("Custo Evitado (Reativo)", f"R$ {cost_avoided:,.2f}")
        res_col5.metric("Valor L√≠quido Gerado", f"R$ {net_value:,.2f}")
        
        st.markdown("<br>", unsafe_allow_html=True)
        st.metric("Retorno sobre o Investimento (ROI)", f"{roi:.2f}%")

def render_export_module(final_model_artifacts, selection_artifacts, processed_df):
    with st.container(border=True):
        st.subheader("Exporta√ß√£o de Resultados e Artefatos")
        st.markdown("Baixe os resultados da an√°lise para uso externo ou para compartilhar com sua equipe.")
        
        y_proba = final_model_artifacts['predictions_proba']
        y_test_index = st.session_state['artifacts']['modeling_data']['y_test'].index
        
        results_df = processed_df.loc[y_test_index].copy()
        results_df['probabilidade_reclamacao'] = y_proba
        
        export_threshold = st.slider("Limiar de risco para lista de clientes:", 0.0, 1.0, 0.5, 0.01, key="export_threshold")
        high_risk_df = results_df[results_df['probabilidade_reclamacao'] >= export_threshold].sort_values('probabilidade_reclamacao', ascending=False)
        
        col1, col2 = st.columns(2)
        with col1:
            st.download_button(label=f"üì• Baixar Lista de {len(high_risk_df)} Clientes de Alto Risco (.csv)", data=high_risk_df.to_csv(index=False).encode('utf-8'), file_name=f"clientes_risco.csv", mime="text/csv", use_container_width=True)
        with col2:
            feature_ranking_df = selection_artifacts['feature_ranking_df']
            st.download_button(label="üì• Baixar Ranking de Features (.csv)", data=feature_ranking_df.to_csv(index=False).encode('utf-8'), file_name="feature_ranking.csv", mime="text/csv", use_container_width=True)


def render_documentation_page():
    st.header("Documenta√ß√£o do Projeto e Metodologia Aplicada")
    st.markdown("Esta se√ß√£o detalha o fluxo de trabalho completo, as ferramentas utilizadas e as justificativas para as decis√µes t√©cnicas tomadas ao longo do projeto.")
    
    st.image("https://images.unsplash.com/photo-1542744173-8e7e53415bb0?ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D&auto=format&fit=crop&w=1770&q=80", use_container_width=True)
    st.markdown("---")

    with st.expander("1. Defini√ß√£o do Problema e Objetivo Estrat√©gico", expanded=True):
        st.markdown("""
        O objetivo central deste projeto √© desenvolver uma solu√ß√£o de Machine Learning capaz de prever, com alta acur√°cia e recall, quais clientes de uma empresa de varejo est√£o mais propensos a registrar uma reclama√ß√£o formal. A identifica√ß√£o proativa desses clientes permite a implementa√ß√£o de estrat√©gias de reten√ß√£o direcionadas, visando reduzir o churn (perda de clientes), otimizar os custos de suporte e aumentar a satisfa√ß√£o e lealdade do cliente. O problema √© modelado como uma **classifica√ß√£o bin√°ria supervisionada** em um contexto de dados altamente desbalanceado.
        """)
    with st.expander("2. Pipeline de Dados: Da Ingest√£o ao Enriquecimento"):
        st.markdown("""
        Um pipeline robusto foi implementado para garantir a qualidade e a relev√¢ncia dos dados utilizados na modelagem:
        - **Auditoria de Dados:** Uma an√°lise de profiling inicial foi executada para identificar e quantificar problemas como valores ausentes, tipos de dados inconsistentes e a presen√ßa de outliers.
        - **Engenharia de Features:** Foram criadas mais de 10 novas vari√°veis para capturar nuances do comportamento do cliente que n√£o estavam expl√≠citas nos dados brutos. Exemplos incluem `Customer_Lifetime_Days`, `Total_Spent`, `Luxury_Purchase_Ratio` e `Marketing_Engagements`.
        - **Tratamento de Dados:** Vari√°veis num√©ricas foram padronizadas via `StandardScaler`. Vari√°veis categ√≥ricas foram convertidas em formato num√©rico usando `One-Hot Encoding` para evitar a cria√ß√£o de uma ordem artificial.
        - **Balanceamento de Classes (SMOTE):** Devido √† raridade de reclama√ß√µes (~1%), a t√©cnica SMOTE foi aplicada **exclusivamente no conjunto de treino** para criar exemplos sint√©ticos da classe minorit√°ria, permitindo que os modelos aprendessem seus padr√µes de forma mais eficaz.
        """)
    with st.expander("3. Estrat√©gia de Modelagem e Avalia√ß√£o"):
        st.markdown("""
        - **Sele√ß√£o de Features (RFECV):** Para combater a "maldi√ß√£o da dimensionalidade" e reduzir o ru√≠do, a t√©cnica RFECV foi utilizada para selecionar automaticamente o subconjunto de features com maior poder preditivo, usando a performance em valida√ß√£o cruzada como crit√©rio.
        - **Modelagem de Baseline:** Um portf√≥lio de 8 algoritmos de classifica√ß√£o foi treinado para estabelecer uma linha de base de performance.
        - **Otimiza√ß√£o (Tuning):** Os melhores modelos da fase de baseline passaram por um processo de otimiza√ß√£o de hiperpar√¢metros com `GridSearchCV`.
        - **M√©tricas Chave:** A **AUC** foi a principal m√©trica para otimiza√ß√£o, e o **Recall** e a **Curva de Precis√£o-Recall** foram utilizados para a an√°lise de neg√≥cio.
        """)

def main():
    """
    Fun√ß√£o principal que orquestra a navega√ß√£o e a renderiza√ß√£o de todas as p√°ginas
    e m√≥dulos da aplica√ß√£o Streamlit.
    """
    st.sidebar.title("Navega√ß√£o Principal üöÄ")
    st.sidebar.markdown("Selecione a p√°gina que deseja visualizar:")
    
    page_options = [
        "P√°gina Inicial", 
        "An√°lise do Dataset", 
        "An√°lise Explorat√≥ria (EDA)",
        "Modelagem e Avalia√ß√£o",
        "An√°lise Avan√ßada e de Neg√≥cio",
        "Documenta√ß√£o do Projeto"
    ]
    
    page_selection = st.sidebar.radio("Menu:", page_options)
    st.sidebar.markdown("---")
    st.sidebar.markdown(
        """
        <div style="text-align: left;">
            Desenvolvido por:
            <h5 style="margin-top: 5px; margin-bottom: 5px;">Pedro Russo</h5>
            <a href="https://www.linkedin.com/in/pedro-richetti-russo-774189297" target="_blank">LinkedIn</a>
        </div>
        """,
        unsafe_allow_html=True
    )

    # ---- L√≥gica de Renderiza√ß√£o de P√°ginas ----
    if page_selection == "P√°gina Inicial":
        display_home_page()

    elif page_selection == "An√°lise do Dataset":
        display_dataset_page()
        
    elif page_selection == "An√°lise Explorat√≥ria (EDA)":
        display_eda_page()
    
    elif page_selection == "Modelagem e Avalia√ß√£o":
        display_modeling_page(st.session_state['processed_df'])

    elif page_selection == "An√°lise Avan√ßada e de Neg√≥cio":
        if st.session_state.get('app_stage') == 'final_model_selected':
            st.header("An√°lise Avan√ßada e de Neg√≥cio", anchor=False, divider='rainbow')
            
            # Re-calcula os artefatos SHAP se ainda n√£o existirem para esta sess√£o
            if 'shap_artifacts' not in st.session_state.get('artifacts', {}):
                 st.session_state['artifacts']['shap_artifacts'] = calculate_global_shap_values(
                     st.session_state['artifacts']['final_model_artifacts'], 
                     st.session_state['artifacts']['modeling_data'], 
                     st.session_state['artifacts']['selection_artifacts']
                 )

            # Estrutura de abas para organizar a p√°gina avan√ßada
            tab_xai, tab_roi, tab_export = st.tabs(["ü§ñ Interpretabilidade (XAI)", "üìà Simula√ß√£o de ROI", "üì§ Exportar"])
            
            with tab_xai:
                render_global_xai_module(st.session_state['artifacts']['final_model_artifacts'], st.session_state['artifacts']['modeling_data'], st.session_state['artifacts']['selection_artifacts'])
                render_local_xai_module(st.session_state['artifacts']['final_model_artifacts'], st.session_state['artifacts']['modeling_data'], st.session_state['artifacts']['selection_artifacts'])
            
            with tab_roi:
                render_business_impact_module(st.session_state['artifacts']['final_model_artifacts'], st.session_state['artifacts']['modeling_data'])
                
            with tab_export:
                render_export_module(st.session_state['artifacts']['final_model_artifacts'], st.session_state['artifacts']['selection_artifacts'], st.session_state['processed_df'])
        else:
            st.warning("Por favor, execute todo o pipeline de modelagem na p√°gina 'Modelagem e Avalia√ß√£o' para acessar esta se√ß√£o.")
    
    elif page_selection == "Documenta√ß√£o do Projeto":
        render_documentation_page()
        
# Ponto de entrada da aplica√ß√£o
if __name__ == "__main__":
    main()